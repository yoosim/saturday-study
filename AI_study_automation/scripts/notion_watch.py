# -*- coding: utf-8 -*-
"""
Notion 'Î¨∏Ï†ú Ï†úÏ∂ú' DB Î≥ÄÍ≤ΩÏùÑ Î™®ÎãàÌÑ∞ÎßÅÌï¥ DiscordÎ°ú ÏïåÎ¶º Ï†ÑÏÜ°

ÌôòÍ≤ΩÎ≥ÄÏàò (.env ÎòêÎäî GitHub Secrets)
- NOTION_API_KEY
- NOTION_DATABASE_ID
- DISCORD_WEBHOOK_URL          # GitHub ActionsÏóêÏÑú secrets.DISCORD_WEBHOOK_NOTION_URLÏùÑ Ïó¨Í∏∞Ïóê Îß§Ìïë

Ïã§Ìñâ Ïòà)
python -m AI_study_automation.scripts.notion_watch
"""

import re
import time
import requests
from datetime import datetime, timedelta, timezone

# Ìå®ÌÇ§ÏßÄ/Í≤ΩÎ°úÏóê Îî∞Îùº Îëò Îã§ ÏßÄÏõê (Ìå®ÌÇ§ÏßÄÎ°úÎèÑ, Ïä§ÌÅ¨Î¶ΩÌä∏Î°úÎèÑ ÎèôÏûë)
try:
    from AI_study_automation.scripts.utils import get_env, post_discord, KST
except Exception:
    from scripts.utils import get_env, post_discord, KST


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ENV
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
NOTION_API_KEY     = get_env("NOTION_API_KEY")
NOTION_DATABASE_ID = get_env("NOTION_DATABASE_ID")

# ‚úÖ YAMLÏóêÏÑú secrets.DISCORD_WEBHOOK_NOTION_URL ‚Üí (env) DISCORD_WEBHOOK_URL Î°ú Îß§ÌïëÌï¥ Ï†ÑÎã¨
DISCORD_WEBHOOK_URL = get_env("DISCORD_WEBHOOK_URL")

HEADERS = {
    "Authorization": f"Bearer {NOTION_API_KEY}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json",
}

URL_RE = re.compile(r"(https?://\S+)", re.IGNORECASE)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Helpers
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def iso_utc(dt: datetime) -> str:
    """datetime ‚Üí ISO 8601 (UTC) Î¨∏ÏûêÏó¥"""
    return dt.astimezone(timezone.utc).isoformat()


def rich_text_to_str(rt) -> str:
    """Notion rich_text[] ‚Üí plain text"""
    if not rt:
        return ""
    return "".join([b.get("plain_text", "") for b in rt])


def extract_links(text: str):
    """ÌÖçÏä§Ìä∏ÏóêÏÑú URLÎßå Ï∂îÏ∂ú(Ï§ëÎ≥µ Ï†úÍ±∞ÌïòÎ©∞ ÏûÖÎ†• ÏàúÏÑú Ïú†ÏßÄ)"""
    links, seen = [], set()
    for u in URL_RE.findall(text or ""):
        if u not in seen:
            seen.add(u)
            links.append(u)
    return links


def page_to_message(page) -> str:
    """
    Notion ÌéòÏù¥ÏßÄ ‚Üí ÎîîÏä§ÏΩîÎìúÏö© Î©îÏãúÏßÄ Ìè¨Îß∑
    ÌïÑÏöîÌïú Notion ÏÜçÏÑ±(Ï†ïÌôïÌïú Ïù¥Î¶Ñ/ÌÉÄÏûÖÏúºÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÏñ¥Ïïº Ìï®):
      - Name (title)
      - Week (date)
      - Submitter (rich_text)
      - Link (url)
      - More Links (rich_text)  # ÎÇ¥Î∂ÄÏóê Ïó¨Îü¨ URLÏù¥ ÏÑûÏó¨ ÏûàÎäî ÏûêÏú† ÌÖçÏä§Ìä∏
    """
    props = page.get("properties", {})

    title     = rich_text_to_str(props.get("Name", {}).get("title", [])) or "(No title)"
    week      = (props.get("Week", {}) or {}).get("date", {}).get("start") or "-"
    submitter = rich_text_to_str(props.get("Submitter", {}).get("rich_text", [])) or "-"
    main_link = (props.get("Link", {}) or {}).get("url") or ""

    more_links_txt = rich_text_to_str(props.get("More Links", {}).get("rich_text", []))
    more_links     = extract_links(more_links_txt)

    lines = [
        "üì£ Notion Î¨∏Ï†ú ÏóÖÎç∞Ïù¥Ìä∏ üì£",
        "",
        f"Î¨∏Ï†ú ÌíÄÏù¥ ÏùºÏãú : {week}",
        f"Î¨∏Ï†ú Ï†úÍ≥µÏûê : {submitter}",
    ]

    idx = 1
    if main_link:
        lines.append(f"Î¨∏Ï†ú {idx} : {main_link}")
        idx += 1
    if len(more_links) >= 1:
        lines.append(f"Î¨∏Ï†ú {idx} : {more_links[0]}")
        idx += 1
    if len(more_links) >= 2:
        lines.append(f"Î¨∏Ï†ú {idx} : {more_links[1]}")
        idx += 1

    remain = max(0, len(more_links) - 2)
    if remain > 0:
        lines.append(f"(More LinksÏóê ÎßÅÌÅ¨ {remain}Í±¥ Ï∂îÍ∞ÄÎ°ú ÏûàÏùå)")

    # Ï†úÎ™© Íº¨Î¶¨Ìëú(ÏõêÏπò ÏïäÏúºÎ©¥ ÏïÑÎûò Ìïú Ï§Ñ Ï†úÍ±∞)
    lines += ["", f"‚Äî {title}"]

    msg = "\n".join(lines)
    # Discord 2000Ïûê Ï†úÌïú ÎåÄÎπÑ
    if len(msg) > 1900:
        msg = msg[:1900] + "\n‚Ä¶(truncated)"
    return msg


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Query & Main
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def query_recent_pages(hours: int = 12):
    """
    ÏµúÍ∑º Ìé∏Ïßë ÌéòÏù¥ÏßÄ Ï°∞Ìöå (Í∏∞Î≥∏: ÏßÄÎÇú 12ÏãúÍ∞Ñ)
    - last_edited_time >= since
    - Ïò§Î¶ÑÏ∞®Ïàú Ï†ïÎ†¨
    """
    since = datetime.now(KST) - timedelta(hours=hours)
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    payload = {
        "filter": {
            "timestamp": "last_edited_time",
            "last_edited_time": {"on_or_after": iso_utc(since)},
        },
        "sorts": [{"timestamp": "last_edited_time", "direction": "ascending"}],
        "page_size": 50,
    }
    r = requests.post(url, headers=HEADERS, json=payload, timeout=25)
    if r.status_code >= 400:
        print("[NOTION][ERROR]", r.status_code, r.text[:300])
    r.raise_for_status()
    return r.json().get("results", [])


def main():
    # ÌïÑÏàò ENV ÌôïÏù∏
    missing = []
    if not NOTION_API_KEY:
        missing.append("NOTION_API_KEY")
    if not NOTION_DATABASE_ID:
        missing.append("NOTION_DATABASE_ID")
    if not DISCORD_WEBHOOK_URL:
        missing.append("DISCORD_WEBHOOK_URL")
    if missing:
        raise RuntimeError(f"Missing environment variables: {', '.join(missing)}")

    pages = query_recent_pages(hours=12)
    if not pages:
        print("[INFO] No recent updates.")
        return

    for idx, page in enumerate(pages, 1):
        content = page_to_message(page)
        try:
            post_discord(DISCORD_WEBHOOK_URL, content=content)
            print(f"[DISCORD] sent {idx}/{len(pages)}")
        except Exception as e:
            print("[DISCORD][EXCEPTION]", repr(e))
        time.sleep(1)


if __name__ == "__main__":
    main()
